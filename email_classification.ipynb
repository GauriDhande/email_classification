{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the libraries\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#importing the csv file\n",
    "df = pd.read_csv('dataset_copy.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#extracting columns to variables\n",
    "out = df['v1']\n",
    "text = df['v2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label = []\n",
    "for val in out:\n",
    "    if(val == 'professional'):\n",
    "        label.append(1)\n",
    "    else:\n",
    "        label.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#convert the lables and test into arrays\n",
    "label = np.array(label)\n",
    "text = np.array(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gauri/.local/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#importing important library documents\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#empty lists\n",
    "x_train = []\n",
    "x_test = []\n",
    "y_train = []\n",
    "y_test = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#spliting the data into training and testing\n",
    "text, label = shuffle(text,label)\n",
    "x_train, x_test, y_train, y_test = train_test_split(text,label,train_size=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#converting the train n test into arrays\n",
    "x_train = np.array(x_train)\n",
    "x_test = np.array(x_test)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Tokeninzing the tarining and data and fitting the data\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CountVectorizer is used to convert a collection of text documents to a matrix of token counts. There is a high probability that the words like 'a', 'an', 'the' etc will occur often. Thus, its a possibility that model might concentrate on these words intead of other important words. TfidfTransformer stands for term frequency and inverse document frequency. It is used to inverse the frequncy of repeatedly occuring words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(270, 4964)\n"
     ]
    }
   ],
   "source": [
    "count_vect = CountVectorizer(decode_error='ignore')\n",
    "x_train_count = count_vect.fit_transform(x_train)\n",
    "tfidf_trans = TfidfTransformer()\n",
    "x_train_tfidf = tfidf_trans.fit_transform(x_train_count).toarray()\n",
    "print(x_train_tfidf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 5189)\n"
     ]
    }
   ],
   "source": [
    "x_test_count = count_vect.transform(x_test)\n",
    "x_test_tfidf = tfidf_trans.transform(x_test_count).toarray()\n",
    "print(x_test_tfidf.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#iimporting the keras model\n",
    "from keras.models import Sequential #type of model\n",
    "from keras.layers import Dense #used to create hidden layers\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create classifier here\n",
    "#Initialising the ANN\n",
    "classifier = Sequential() # classifier is as object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "270/270 [==============================] - 0s - loss: 0.6884 - acc: 0.8481     \n",
      "Epoch 2/50\n",
      "270/270 [==============================] - 0s - loss: 0.6776 - acc: 0.8778     \n",
      "Epoch 3/50\n",
      "270/270 [==============================] - 0s - loss: 0.6643 - acc: 0.8778     \n",
      "Epoch 4/50\n",
      "270/270 [==============================] - 0s - loss: 0.6432 - acc: 0.8778     \n",
      "Epoch 5/50\n",
      "270/270 [==============================] - 0s - loss: 0.6002 - acc: 0.8778     \n",
      "Epoch 6/50\n",
      "270/270 [==============================] - 0s - loss: 0.5296 - acc: 0.8778     \n",
      "Epoch 7/50\n",
      "270/270 [==============================] - 0s - loss: 0.4388 - acc: 0.8778     \n",
      "Epoch 8/50\n",
      "270/270 [==============================] - 0s - loss: 0.3917 - acc: 0.8778     \n",
      "Epoch 9/50\n",
      "270/270 [==============================] - 0s - loss: 0.3573 - acc: 0.8778     \n",
      "Epoch 10/50\n",
      "270/270 [==============================] - 0s - loss: 0.3532 - acc: 0.8778     \n",
      "Epoch 11/50\n",
      "270/270 [==============================] - 0s - loss: 0.3272 - acc: 0.8778     \n",
      "Epoch 12/50\n",
      "270/270 [==============================] - 0s - loss: 0.3059 - acc: 0.8778     \n",
      "Epoch 13/50\n",
      "270/270 [==============================] - 0s - loss: 0.3007 - acc: 0.8778     \n",
      "Epoch 14/50\n",
      "270/270 [==============================] - 0s - loss: 0.2754 - acc: 0.8778     \n",
      "Epoch 15/50\n",
      "270/270 [==============================] - 0s - loss: 0.2750 - acc: 0.8778     \n",
      "Epoch 16/50\n",
      "270/270 [==============================] - 0s - loss: 0.2468 - acc: 0.8778     \n",
      "Epoch 17/50\n",
      "270/270 [==============================] - 0s - loss: 0.2285 - acc: 0.9037     \n",
      "Epoch 18/50\n",
      "270/270 [==============================] - 0s - loss: 0.2175 - acc: 0.9074     \n",
      "Epoch 19/50\n",
      "270/270 [==============================] - 0s - loss: 0.1973 - acc: 0.9222     \n",
      "Epoch 20/50\n",
      "270/270 [==============================] - 0s - loss: 0.1876 - acc: 0.9370     \n",
      "Epoch 21/50\n",
      "270/270 [==============================] - 0s - loss: 0.1641 - acc: 0.9370     \n",
      "Epoch 22/50\n",
      "270/270 [==============================] - 0s - loss: 0.1493 - acc: 0.9407     \n",
      "Epoch 23/50\n",
      "270/270 [==============================] - 0s - loss: 0.1559 - acc: 0.9519     \n",
      "Epoch 24/50\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.1214 - acc: 0.966 - 0s - loss: 0.1298 - acc: 0.9667     \n",
      "Epoch 25/50\n",
      "270/270 [==============================] - 0s - loss: 0.1182 - acc: 0.9741     \n",
      "Epoch 26/50\n",
      "270/270 [==============================] - 0s - loss: 0.1116 - acc: 0.9704     \n",
      "Epoch 27/50\n",
      "270/270 [==============================] - 0s - loss: 0.1114 - acc: 0.9667     \n",
      "Epoch 28/50\n",
      "270/270 [==============================] - 0s - loss: 0.0988 - acc: 0.9667     \n",
      "Epoch 29/50\n",
      "270/270 [==============================] - 0s - loss: 0.0930 - acc: 0.9778     \n",
      "Epoch 30/50\n",
      "270/270 [==============================] - 0s - loss: 0.0811 - acc: 0.9778     \n",
      "Epoch 31/50\n",
      "270/270 [==============================] - 0s - loss: 0.0837 - acc: 0.9778     \n",
      "Epoch 32/50\n",
      "270/270 [==============================] - 0s - loss: 0.0843 - acc: 0.9778     \n",
      "Epoch 33/50\n",
      "270/270 [==============================] - 0s - loss: 0.0614 - acc: 0.9926     \n",
      "Epoch 34/50\n",
      "270/270 [==============================] - 0s - loss: 0.0677 - acc: 0.9815     \n",
      "Epoch 35/50\n",
      "270/270 [==============================] - 0s - loss: 0.0641 - acc: 0.9852     \n",
      "Epoch 36/50\n",
      "270/270 [==============================] - 0s - loss: 0.0517 - acc: 0.9889     \n",
      "Epoch 37/50\n",
      "270/270 [==============================] - 0s - loss: 0.0726 - acc: 0.9778     \n",
      "Epoch 38/50\n",
      "270/270 [==============================] - 0s - loss: 0.0496 - acc: 0.9926     - ETA: 0s - loss: 0.0580 - acc: 0.986\n",
      "Epoch 39/50\n",
      "270/270 [==============================] - 0s - loss: 0.0532 - acc: 0.9926     \n",
      "Epoch 40/50\n",
      "270/270 [==============================] - 0s - loss: 0.0437 - acc: 0.9926     \n",
      "Epoch 41/50\n",
      "270/270 [==============================] - 0s - loss: 0.0544 - acc: 0.9815     - ETA: 0s - loss: 0.0487 - acc: 0.98\n",
      "Epoch 42/50\n",
      "270/270 [==============================] - 0s - loss: 0.0487 - acc: 0.9889     \n",
      "Epoch 43/50\n",
      "270/270 [==============================] - 0s - loss: 0.0620 - acc: 0.9778     \n",
      "Epoch 44/50\n",
      "270/270 [==============================] - 0s - loss: 0.0386 - acc: 0.9889     \n",
      "Epoch 45/50\n",
      "270/270 [==============================] - 0s - loss: 0.0579 - acc: 0.9778     \n",
      "Epoch 46/50\n",
      "270/270 [==============================] - 0s - loss: 0.0356 - acc: 0.9926     \n",
      "Epoch 47/50\n",
      "270/270 [==============================] - 0s - loss: 0.0341 - acc: 0.9926     \n",
      "Epoch 48/50\n",
      "270/270 [==============================] - 0s - loss: 0.0403 - acc: 0.9889     \n",
      "Epoch 49/50\n",
      "270/270 [==============================] - 0s - loss: 0.0450 - acc: 0.9815     \n",
      "Epoch 50/50\n",
      "270/270 [==============================] - 0s - loss: 0.0281 - acc: 0.9926     \n"
     ]
    }
   ],
   "source": [
    "#Adding the hidden layers\n",
    "#Note: shuffuling may change the dimensions of input arrays\n",
    "classifier.add(Dense(output_dim = 6, init = 'uniform', activation = 'relu', input_dim = x_train_tfidf.shape[1]))\n",
    "classifier.add(Dropout(rate = 0.1))\n",
    "#Adding Second Hidden Layer\n",
    "classifier.add(Dense(output_dim = 6, init = 'uniform', activation = 'relu'))\n",
    "classifier.add(Dropout(rate = 0.1))\n",
    "#Adding final/output layer\n",
    "classifier.add(Dense(output_dim = 1, init = 'uniform', activation = 'sigmoid'))\n",
    "#Compiling the ANN\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "#fitting ANN to trainig set\n",
    "hist = classifier.fit(x_train_tfidf, y_train, batch_size = 10, epochs = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9998498 ]\n",
      " [0.99921024]\n",
      " [0.9838223 ]\n",
      " [0.886614  ]\n",
      " [0.9999616 ]\n",
      " [0.99940264]\n",
      " [0.99970144]\n",
      " [0.9999641 ]\n",
      " [0.9954873 ]\n",
      " [0.98762786]\n",
      " [0.9986052 ]\n",
      " [0.9995296 ]\n",
      " [0.99919754]\n",
      " [0.9983999 ]\n",
      " [0.99432606]\n",
      " [0.968519  ]\n",
      " [0.5506767 ]\n",
      " [0.9991328 ]\n",
      " [0.98797464]\n",
      " [0.99777824]\n",
      " [0.73122275]\n",
      " [0.9989567 ]\n",
      " [0.9986381 ]\n",
      " [0.99972004]\n",
      " [0.9404081 ]\n",
      " [0.99977034]\n",
      " [0.9960288 ]\n",
      " [0.9999728 ]\n",
      " [0.9971328 ]\n",
      " [0.99088216]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = classifier.predict(x_test_tfidf)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acc': [0.8740740661267881,\n",
       "  0.877777772921103,\n",
       "  0.877777772921103,\n",
       "  0.8777777751286825,\n",
       "  0.8777777662983647,\n",
       "  0.8777777685059441,\n",
       "  0.8777777707135236,\n",
       "  0.877777772921103,\n",
       "  0.8777777662983647,\n",
       "  0.8777777707135236,\n",
       "  0.8777777751286825,\n",
       "  0.8777777662983647,\n",
       "  0.8777777707135236,\n",
       "  0.8777777707135236,\n",
       "  0.8777777685059441,\n",
       "  0.877777772921103,\n",
       "  0.877777772921103,\n",
       "  0.8777777751286825,\n",
       "  0.8777777662983647,\n",
       "  0.877777772921103,\n",
       "  0.8777777685059441,\n",
       "  0.8777777751286825,\n",
       "  0.877777772921103,\n",
       "  0.8777777685059441,\n",
       "  0.8777777707135236,\n",
       "  0.8777777707135236,\n",
       "  0.8777777662983647,\n",
       "  0.8777777707135236,\n",
       "  0.8777777685059441,\n",
       "  0.8777777707135236,\n",
       "  0.8777777685059441,\n",
       "  0.877777772921103,\n",
       "  0.8777777685059441,\n",
       "  0.8777777707135236,\n",
       "  0.877777772921103,\n",
       "  0.877777772921103,\n",
       "  0.8777777773362619,\n",
       "  0.8777777707135236,\n",
       "  0.8777777685059441,\n",
       "  0.877777772921103,\n",
       "  0.877777772921103,\n",
       "  0.8777777751286825,\n",
       "  0.8777777751286825,\n",
       "  0.8777777707135236,\n",
       "  0.8777777773362619,\n",
       "  0.877777772921103,\n",
       "  0.8777777662983647,\n",
       "  0.877777772921103,\n",
       "  0.877777772921103,\n",
       "  0.8777777662983647],\n",
       " 'loss': [0.6875365155714529,\n",
       "  0.6738571546695851,\n",
       "  0.6558442755981728,\n",
       "  0.6281701723734537,\n",
       "  0.5959098317005016,\n",
       "  0.5517406684380991,\n",
       "  0.5047695404953427,\n",
       "  0.45992853464903655,\n",
       "  0.421401501805694,\n",
       "  0.386958552731408,\n",
       "  0.36633170313305324,\n",
       "  0.356776073023125,\n",
       "  0.3410029063622157,\n",
       "  0.3300188644616692,\n",
       "  0.3359736662220072,\n",
       "  0.3269764822390344,\n",
       "  0.29977484461334014,\n",
       "  0.3204754055650146,\n",
       "  0.3360321535556405,\n",
       "  0.3182817256009137,\n",
       "  0.3113858410053783,\n",
       "  0.3097211660610305,\n",
       "  0.30164787697571294,\n",
       "  0.30054304417636657,\n",
       "  0.2982307620070599,\n",
       "  0.29950217295576026,\n",
       "  0.28592148230031683,\n",
       "  0.2863038240207566,\n",
       "  0.27696322511743615,\n",
       "  0.2768578340333921,\n",
       "  0.28443729629119235,\n",
       "  0.2625201882587539,\n",
       "  0.26831049582472555,\n",
       "  0.272772467246762,\n",
       "  0.2606755906233081,\n",
       "  0.2583989019471186,\n",
       "  0.24703476715970923,\n",
       "  0.24345861402926622,\n",
       "  0.23633058520930786,\n",
       "  0.2286493713381114,\n",
       "  0.22739967786603504,\n",
       "  0.2130601646171676,\n",
       "  0.22429249711610652,\n",
       "  0.20880635441453368,\n",
       "  0.20292913851638636,\n",
       "  0.18858629520292636,\n",
       "  0.18255219787911134,\n",
       "  0.1730986770104479,\n",
       "  0.1717357407151549,\n",
       "  0.1704987260616488]}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8777036971074562\n"
     ]
    }
   ],
   "source": [
    "#average accuracy\n",
    "mean = np.mean(hist.history['acc'])\n",
    "print(mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
